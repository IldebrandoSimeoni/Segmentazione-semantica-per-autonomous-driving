{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " ScriptTesiFinale.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvwdgOdsE3gV"
      },
      "source": [
        "#Tesi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViRFV3r0Eycv"
      },
      "source": [
        "##Download dei dati\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXTmhEu5FZ6X"
      },
      "source": [
        "###Download cityscapes \"gtFine_trainvaltest\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbmDcjcLzk25"
      },
      "source": [
        "!wget -P /content/drive/MyDrive/Tesi --keep-session-cookies --save-cookies=cookies.txt --post-data  https://www.cityscapes-dataset.com/login/\n",
        "!wget -P /content/drive/MyDrive/Tesi --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZnXFOCBKwK-"
      },
      "source": [
        "%cd /content/drive/MyDrive/Tesi\n",
        "!pwd\n",
        "!unzip gtFine_trainvaltest.zip  -d /content/drive/MyDrive/Tesi/gtFine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFGnyLGFFcye"
      },
      "source": [
        "###Download CityScapes \"leftImg8bit_trainvaltest\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUS0cy7mFi9h"
      },
      "source": [
        "!wget -P /content/drive/MyDrive/Tesi --keep-session-cookies --save-cookies=cookies.txt --post-data  https://www.cityscapes-dataset.com/login/\n",
        "!wget -P /content/drive/MyDrive/Tesi --load-cookies cookies.txt --content-disposition https://www.cityscapes-dataset.com/file-handling/?packageID=3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2tGHc-iLLqN"
      },
      "source": [
        "%cd /content/drive/MyDrive/Tesi\n",
        "!pwd\n",
        "!unzip leftImg8bit_trainvaltest.zip  -d /content/drive/MyDrive/Tesi/leftImg8bit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnqNtZ3m_2ER"
      },
      "source": [
        "from __future__ import division\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.layers import Layer, InputSpec\n",
        "import random\n",
        "import os.path\n",
        "import scipy.misc\n",
        "import shutil\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "from collections import namedtuple\n",
        "from timeit import default_timer as timer\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Concatenate, Activation, add\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Convolution2DTranspose, BatchNormalization\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import os\n",
        "from skimage import io\n",
        "import scipy\n",
        "from keras.utils.generic_utils import CustomObjectScope\n",
        "from PIL import Image\n",
        "from keras.applications import mobilenet\n",
        "from keras.layers import ReLU#\n",
        "from keras.layers import DepthwiseConv2D#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1Xos3x_CbyO"
      },
      "source": [
        "##Normalizzazione L2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FODurxEoDCTI"
      },
      "source": [
        "class L2Normalization(Layer):\n",
        "    def __init__(self, gamma_init=20, **kwargs):\n",
        "        if K.image_data_format() =='channels_last': \n",
        "            self.axis = 3\n",
        "        else:\n",
        "            self.axis = 1\n",
        "        self.gamma_init = gamma_init\n",
        "        super(L2Normalization, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "        gamma = self.gamma_init * np.ones((input_shape[self.axis],))\n",
        "        self.gamma = K.variable(gamma, name='{}_gamma'.format(self.name))\n",
        "        self._trainable_weights = [self.gamma]\n",
        "        super(L2Normalization, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        output = K.l2_normalize(x,self.axis)\n",
        "        return output * self.gamma\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'gamma_init': self.gamma_init\n",
        "        }\n",
        "        base_config = super(L2Normalization, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBl9GDRSCvO3"
      },
      "source": [
        "##Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvCKnKH1DC_t"
      },
      "source": [
        "Label = namedtuple('Label', ['name', 'color'])\n",
        "\n",
        "label_defs = [\n",
        "    Label('unlabeled',     (0,     0,   0)), Label('dynamic',       (111,  74,   0)),\n",
        "    Label('ground',        ( 81,   0,  81)), Label('road',          (128,  64, 128)),\n",
        "    Label('sidewalk',      (244,  35, 232)), Label('parking',       (250, 170, 160)),\n",
        "    Label('rail track',    (230, 150, 140)), Label('building',      ( 70,  70,  70)),\n",
        "    Label('wall',          (102, 102, 156)), Label('fence',         (190, 153, 153)),\n",
        "    Label('guard rail',    (180, 165, 180)), Label('bridge',        (150, 100, 100)),\n",
        "    Label('tunnel',        (150, 120,  90)), Label('pole',          (153, 153, 153)),\n",
        "    Label('traffic light', (250, 170,  30)), Label('traffic sign',  (220, 220,   0)),\n",
        "    Label('vegetation',    (107, 142,  35)), Label('terrain',       (152, 251, 152)),\n",
        "    Label('sky',           ( 70, 130, 180)), Label('person',        (220,  20,  60)),\n",
        "    Label('rider',         (255,   0,   0)), Label('car',           (  0,   0, 142)),\n",
        "    Label('truck',         (  0,   0,  70)), Label('bus',           (  0,  60, 100)),\n",
        "    Label('caravan',       (  0,   0,  90)), Label('trailer',       (  0,   0, 110)),\n",
        "    Label('train',         (  0,  80, 100)), Label('motorcycle',    (  0,   0, 230)),\n",
        "    Label('bicycle',       (119,  11,  32)), Label('pole group',    (153, 153, 153)),]\n",
        "\n",
        "    \n",
        "def build_file_list(images_root, labels_root, sample_name):\n",
        "    image_sample_root = images_root + '/' + sample_name\n",
        "    image_root_len = len(image_sample_root)\n",
        "    label_sample_root = labels_root + '/' + sample_name\n",
        "    image_files = glob(image_sample_root + '/**/*png')\n",
        "    file_list = []\n",
        "    for f in image_files:\n",
        "        f_relative = f[image_root_len:]\n",
        "        f_dir = os.path.dirname(f_relative)\n",
        "        f_base = os.path.basename(f_relative)\n",
        "        f_base_gt = f_base.replace('leftImg8bit', 'gtFine_color')\n",
        "        f_label = label_sample_root + f_dir + '/' + f_base_gt\n",
        "        if os.path.exists(f_label):\n",
        "            file_list.append((f, f_label))\n",
        "    return file_list\n",
        "\n",
        "\n",
        "def load_data(data_folder):\n",
        "\n",
        "    images_root = os.path.join(data_folder, 'leftImg8bit')\n",
        "    labels_root = os.path.join(data_folder, 'gtFine')\n",
        "\n",
        "    train_images = build_file_list(images_root, labels_root, 'train')\n",
        "    valid_images = build_file_list(images_root, labels_root, 'val')\n",
        "    test_images = build_file_list(images_root, labels_root, 'test')\n",
        "    num_classes = len(label_defs)\n",
        "    label_colors = {i: np.array(l.color) for i, l in enumerate(label_defs)}\n",
        "    \n",
        "    return train_images, valid_images, test_images, num_classes, label_colors \n",
        "\n",
        "\n",
        "def bc_img(img, s=1.0, m=0.0):\n",
        "    img = img.astype(np.int)\n",
        "    img = img * s + m\n",
        "    img[img > 255] = 255\n",
        "    img[img < 0] = 0\n",
        "    img = img.astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "\n",
        "def gen_batch_function(image_paths, image_shape, test = False):\n",
        "   \n",
        "    def get_batches_fn(batch_size):\n",
        "       \n",
        "        random.shuffle(image_paths)\n",
        "\n",
        "        while True:\n",
        "\n",
        "            for batch_i in range(0, len(image_paths), batch_size):\n",
        "                image_files = image_paths[batch_i:batch_i+batch_size]\n",
        "\n",
        "                images = []\n",
        "                labels = []\n",
        "\n",
        "                for f in image_files:\n",
        "                    image_file = f[0]\n",
        "                    gt_image_file = f[1]\n",
        "                    image =np.array(Image.fromarray(imageio.imread(image_file)).resize((image_shape[1],image_shape[0])))\n",
        "                    gt_image =np.array(Image.fromarray(imageio.imread(gt_image_file,as_gray=False, pilmode=\"RGB\")).resize((image_shape[1],image_shape[0])))\n",
        "                    contrast = random.uniform(0.85, 1.15)  # Contrast augmentation\n",
        "                    bright = random.randint(-45, 30)  # Brightness augmentation\n",
        "                    image = bc_img(image, contrast, bright)\n",
        "\n",
        "                    label_bg = np.zeros([image_shape[0], image_shape[1]], dtype=bool)\n",
        "                    label_list = []\n",
        "                    for ldef in label_defs[1:]:\n",
        "                        \n",
        "                        x=np.abs(np.float32(gt_image[:,:,0])-ldef.color[0])+np.abs(np.float32(gt_image[:,:,1])-ldef.color[1])+np.abs(np.float32(gt_image[:,:,2])-ldef.color[2])\n",
        "                        label_current=x<90\n",
        "                        label_bg |= label_current                   \n",
        "                        label_list.append(label_current)\n",
        "\n",
        "                    label_bg = ~label_bg\n",
        "                    label_all = np.dstack([label_bg, *label_list])\n",
        "\n",
        "                    label_all = label_all.astype(np.float32)\n",
        "                    \n",
        "                    images.append(image)\n",
        "                    labels.append(label_all)\n",
        "                    \n",
        "                if not test:\n",
        "                    yield np.array(images), np.array(labels)\n",
        "                else:\n",
        "                    yield np.array(images)\n",
        "    return get_batches_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDKeyKu5Cy8v"
      },
      "source": [
        "##Definizione Rete"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4xgb-9JDDqU"
      },
      "source": [
        "class squeeze_segNet():\n",
        "\n",
        "    def __init__(self, n_labels, image_shape, weights_path):\n",
        "        self.n_labels = n_labels\n",
        "        self.image_shape = image_shape\n",
        "        self.pretrain_weights_path = weights_path\n",
        "        pass\n",
        "\n",
        "    def fire_module(self, x, filters, name=\"fire\"):\n",
        "        sq_filters, ex1_filters, ex2_filters = filters\n",
        "        squeeze = Convolution2D(sq_filters, (1, 1), activation='elu', padding='same', name=name + \"_squeeze1x1\")(x)\n",
        "        expand1 = Convolution2D(ex1_filters, (1, 1), activation='elu', padding='same', name=name + \"_expand1x1\")(squeeze)\n",
        "        expand2 = Convolution2D(ex2_filters, (3, 3), activation='elu', padding='same', name=name + \"_expand3x3\")(squeeze)\n",
        "        x = Concatenate(axis=-1, name=name)([expand1, expand2])\n",
        "        return x\n",
        "\n",
        "    def squeeze_net(self, x):\n",
        "        \n",
        "        x = Convolution2D(64, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", activation=\"elu\", name='conv1')(x)\n",
        "        x_low1 = x\n",
        "\n",
        "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool1', padding=\"same\")(x)\n",
        "\n",
        "        x = self.fire_module(x, (16, 64, 64), name=\"fire2\")\n",
        "        x = self.fire_module(x, (16, 64, 64), name=\"fire3\")\n",
        "\n",
        "        x_low2 = x\n",
        "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool3', padding=\"same\")(x)\n",
        "\n",
        "        x = self.fire_module(x, (32, 128, 128), name=\"fire4\")\n",
        "        x = self.fire_module(x, (32, 128, 128), name=\"fire5\")\n",
        "\n",
        "        x_low3 = x\n",
        "        x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='maxpool5', padding=\"same\")(x)\n",
        "\n",
        "        x = self.fire_module(x, (48, 192, 192), name=\"fire6\")\n",
        "        x = self.fire_module(x, (48, 192, 192), name=\"fire7\")\n",
        "\n",
        "        x = self.fire_module(x, (64, 256, 256), name=\"fire8\")\n",
        "        x = self.fire_module(x, (64, 256, 256), name=\"fire9\")\n",
        "\n",
        "        return x, x_low1, x_low2, x_low3\n",
        "\n",
        "    def paral_dilat_module(self, x, n_filter=128):\n",
        "        \n",
        "        x1 = Convolution2D(64, kernel_size=(3,3), dilation_rate=(1,1), activation='elu', kernel_initializer='he_normal', padding='same', name='dilat1')(x)\n",
        "        x2 = Convolution2D(64, kernel_size=(3,3), dilation_rate=(3,3), activation='elu', kernel_initializer='he_normal', padding='same', name='dilat2')(x)\n",
        "        x3 = Convolution2D(64, kernel_size=(3,3), dilation_rate=(5,5), activation='elu', kernel_initializer='he_normal', padding='same', name='dilat3')(x)\n",
        "        x4 = Convolution2D(64, kernel_size=(3,3), dilation_rate=(7,7), activation='elu', kernel_initializer='he_normal', padding='same', name='dilat4')(x)\n",
        "\n",
        "        x_sum = add([x1, x2, x3, x4])\n",
        "\n",
        "        return x_sum\n",
        "    \n",
        "    def conv_trans_block(self, x, out_filters, name_trans):\n",
        "\n",
        "        x = Convolution2DTranspose(64, (1, 1), activation='elu', padding='same', kernel_initializer='he_normal', name=name_trans+'_tran1')(x)\n",
        "        x = Convolution2DTranspose(64, (3, 3), strides=(2, 2), activation='elu', padding='same', kernel_initializer='he_normal', name=name_trans+'_tran2')(x)\n",
        "        x = Convolution2DTranspose(out_filters, (1, 1), activation='elu', padding='same', kernel_initializer='he_normal', name=name_trans+'_tran3')(x)\n",
        "\n",
        "        return x \n",
        "    \n",
        "    def refine_block(self, x, x_low, refine_name):\n",
        "        x = Convolution2D(64, kernel_size=(3,3), activation='elu', kernel_initializer='he_normal', padding='same', name=refine_name+'_block1')(x)\n",
        "        \n",
        "        x = L2Normalization(gamma_init=20, name=refine_name+'l2_norm1')(x)\n",
        "\n",
        "        x_low = Convolution2D(64, kernel_size=(3,3), activation='elu', kernel_initializer='he_normal', padding='same', name=refine_name+'_block2')(x_low)\n",
        "        \n",
        "        x_low = L2Normalization(gamma_init=20, name=refine_name+'l2_norm2')(x_low)\n",
        "\n",
        "        \n",
        "        x_sum1 = add([x, x_low])\n",
        "\n",
        "        return x_sum1\n",
        "\n",
        "    def conv_transpose(self, x, x_low1, x_low2, x_low3):\n",
        "        x = self.conv_trans_block(x, 256, name_trans='tran1')\n",
        "        x = self.refine_block(x, x_low3, refine_name='refine1')\n",
        "        x = self.conv_trans_block(x, 128, name_trans='tran2')\n",
        "        x = self.refine_block(x, x_low2, refine_name= 'refine2')\n",
        "        x = self.conv_trans_block(x, 64, name_trans='tran3')\n",
        "        x = self.refine_block(x, x_low1, refine_name='refine3')\n",
        "        x = Convolution2DTranspose(64, (3, 3), strides=(2, 2), activation='elu', padding='same', kernel_initializer='he_normal', name='lasttran')(x)\n",
        "        x = Convolution2D(self.n_labels, kernel_size=(1,1), activation='softmax', kernel_initializer='he_normal', padding='same', name='lastconv')(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "    def init_model(self):\n",
        "        h, w, d = self.image_shape\n",
        "\n",
        "        input1 = Input(shape=(h,w,d), name='input')\n",
        "        output1, x_low1, x_low2, x_low3 = self.squeeze_net(input1)\n",
        "        \n",
        "        output_3 = self.paral_dilat_module(output1)\n",
        "        result = self.conv_transpose(output_3, x_low1, x_low2, x_low3)\n",
        "\n",
        "        squeeze_seg = Model(inputs=input1, outputs=result, name='squeeze_seg')\n",
        "        opt = tf.keras.optimizers.RMSprop(learning_rate = 1e-4, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "        squeeze_seg.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[iou_metric])\n",
        "\n",
        "        return squeeze_seg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6rbOtOhC2PP"
      },
      "source": [
        "##Training e Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwG_A1FwDEmN"
      },
      "source": [
        "  def iou_metric(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        Indice prestazionale per la segmentazione chiamato Intersection-over-Union o Jaccard index.\n",
        "        IoU = (|X & Y|)/ (|X| + |Y| - |X & Y|)\n",
        "        \"\"\"\n",
        "        yt = y_true[:,:,:,-1:] > 0.5\n",
        "        yp = y_pred[:,:,:,-1:] > 0.5\n",
        "        intersection = K.sum(K.cast_to_floatx(yt & yp), axis=(1,2))\n",
        "        union = K.sum(K.cast_to_floatx(yt | yp), axis=(1,2))\n",
        "        iou = intersection / K.maximum(union, 0.01)  # the maximum is used to avoid the divisions with zero\n",
        "        return iou    \n",
        "\n",
        "\n",
        "def train(n_labels, batch_size, epochs, train_steps, val_steps, saved_weight, input_shape, pre_weight, train_generator, valid_generator):\n",
        "    \n",
        "    os.path.dirname(saved_weight)\n",
        "    os.makedirs(os.path.dirname(saved_weight),exist_ok=True)\n",
        "        \n",
        "\n",
        "    context_Net = squeeze_segNet(n_labels=n_labels, image_shape=input_shape, weights_path = pre_weight)\n",
        "    model = context_Net.init_model()\n",
        "    \n",
        "                                                      \n",
        "    chk = keras.callbacks.ModelCheckpoint(saved_weight, monitor='val_iou_metric', verbose=0, save_best_only=True, \n",
        "                                                                      save_weights_only=True, mode='auto', save_freq='epoch')\n",
        "    \n",
        "    model.fit(train_generator(batch_size), steps_per_epoch=train_steps, epochs=epochs, verbose=1, callbacks=chk,\n",
        "                                                                        validation_data = valid_generator(batch_size), validation_steps=train_steps)\n",
        "  \n",
        "def build_pridictor(output_last, label_colors, image_shape):\n",
        "   \n",
        "    labels = np.argmax(output_last, axis=-1)\n",
        "    labels = labels.reshape(image_shape[0], image_shape[1])\n",
        "    labels_colored = np.zeros((image_shape[0], image_shape[1], 3)) \n",
        "\n",
        "    for label, color in label_colors.items():\n",
        "        labels_colored[labels == label] = color\n",
        "\n",
        "    return labels_colored\n",
        "\n",
        "def test(batch_size, test_steps, image_shape, saved_preImage, saved_weight, label_colors, test_generator,n_labels,input_shape, pre_weight):\n",
        "   \n",
        "    if not os.path.exists(saved_preImage):\n",
        "        os.makedirs(saved_preImage)\n",
        "        #pass\n",
        "\n",
        "    context_Net = squeeze_segNet(n_labels=n_labels, image_shape=input_shape, weights_path = pre_weight)\n",
        "    model = context_Net.init_model()\n",
        "    \n",
        "    model.load_weights(saved_weight)\n",
        "    \n",
        "    predicted = model.predict_generator(test_generator(batch_size), steps=test_steps)\n",
        "    for index, image in enumerate(predicted):\n",
        "        saved_images = os.path.join(saved_preImage, str(index)+'.png')\n",
        "        pred_image = build_pridictor(image, label_colors, image_shape)\n",
        "        pred_image =np.array(Image.fromarray(np.uint8(pred_image*255)).resize((512,256)))\n",
        "        cv2.imwrite(saved_images, cv2.cvtColor(pred_image, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Triennale/Tesi/Datasets'  # the path of the dataset\n",
        "pre_weight = None \n",
        "saved_weight = os.path.join(data_dir, 'sq_weight.h5')  \n",
        "saved_preImage = os.path.join(data_dir, 'test') # the path to save the predicted results\n",
        "\n",
        "image_shape = (128, 256, 3)  # the shape of the input images of the model\n",
        "target_shape = (128, 256)\n",
        "\n",
        "batch_size = 5\n",
        "epochs = 2\n",
        "\n",
        "\n",
        "train_images, valid_images, test_images, num_classes, label_colors = load_data(data_dir)\n",
        "\n",
        "train_steps =int(len(train_images)/batch_size) \n",
        "val_steps =int(len(valid_images)/batch_size) \n",
        "test_steps = int(len(test_images)/batch_size) \n",
        "\n",
        "\n",
        "get_train_image = gen_batch_function(train_images, image_shape[0:2])\n",
        "get_val_image =gen_batch_function(valid_images, image_shape[0:2])\n",
        "get_test_image =gen_batch_function(test_images, image_shape[0:2], test=True)\n",
        "\n",
        "                                                                                \n",
        "train(num_classes, batch_size, epochs, train_steps, val_steps, saved_weight, image_shape, pre_weight, get_train_image, get_val_image)\n",
        "test(batch_size, test_steps, target_shape, saved_preImage, saved_weight, label_colors, get_test_image,num_classes,image_shape,pre_weight)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9tarOWDIt_z"
      },
      "source": [
        "##Test v 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPpkTlmkvxO-"
      },
      "source": [
        "def test2(batch_size, test_steps, image_shape, saved_preImage, saved_weight, label_colors, test_generator,n_labels,input_shape, pre_weight):\n",
        "    \n",
        "    if not os.path.exists(saved_preImage):\n",
        "        os.makedirs(saved_preImage)\n",
        "        #pass\n",
        "\n",
        "    context_Net = squeeze_segNet(n_labels=n_labels, image_shape=input_shape, weights_path = pre_weight)\n",
        "    model = context_Net.init_model()\n",
        "    model.load_weights(saved_weight)\n",
        "    \n",
        "    x = model.evaluate(test_generator(batch_size), steps=test_steps,return_dict=True )\n",
        "    print(x)\n",
        "\n",
        "    for image,labels in test_generator(batch_size):\n",
        "      predict=model.predict(image)\n",
        "      for index in range (len(labels)):\n",
        "        gt=labels[index]\n",
        "        out=predict[index]\n",
        "        saved_images = os.path.join(saved_preImage, str(index)+'_gt.png')\n",
        "        pred_image = build_pridictor(gt, label_colors, image_shape)\n",
        "        pred_image =np.array(Image.fromarray(np.uint8(pred_image*255)).resize((512,256)))\n",
        "        cv2.imwrite(saved_images, cv2.cvtColor(pred_image, cv2.COLOR_RGB2BGR))\n",
        "        saved_images = os.path.join(saved_preImage, str(index)+'_out.png')\n",
        "        pred_image = build_pridictor(out, label_colors, image_shape)\n",
        "        pred_image =np.array(Image.fromarray(np.uint8(pred_image*255)).resize((512,256)))\n",
        "        cv2.imwrite(saved_images, cv2.cvtColor(pred_image, cv2.COLOR_RGB2BGR))\n",
        "      break\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8iSRN19xBgV"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/Triennale/Tesi/Datasets'  # the path of the dataset\n",
        "pre_weight = None \n",
        "saved_weight = os.path.join(data_dir, 'sq_weight.h5')  # the path to save the entire the model\n",
        "saved_preImage = os.path.join(data_dir, 'test') # the path to save the predicted results\n",
        "\n",
        "image_shape = (128, 256, 3)  # the shape of the input images of the model\n",
        "target_shape = (128, 256)\n",
        "\n",
        "batch_size = 5\n",
        "epochs = 10\n",
        "\n",
        "\n",
        "train_images, valid_images, test_images, num_classes, label_colors = load_data(data_dir)\n",
        "\n",
        "train_steps = 5 \n",
        "val_steps = 5 \n",
        "test_steps = 5 \n",
        "print(train_steps, val_steps, test_steps)\n",
        "\n",
        "get_train_image = gen_batch_function(train_images, image_shape[0:2])\n",
        "get_val_image =gen_batch_function(valid_images, image_shape[0:2])\n",
        "get_test_image =gen_batch_function(test_images, image_shape[0:2], test=True)\n",
        "\n",
        "                                                            \n",
        "test2(batch_size, test_steps, target_shape, saved_preImage, saved_weight, label_colors, get_val_image,num_classes,image_shape,pre_weight)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}